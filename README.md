# üß† Parallel Text Processor
### Accelerating NLP Workflows with Parallel Computing and Topic Modeling

## üìò Overview
The **Parallel Text Processor** is a system designed to process large text datasets efficiently using **parallel processing** and **advanced NLP techniques**.  
It compares traditional and modern topic modeling methods ‚Äî **Latent Dirichlet Allocation (LDA)** and **K-Means with Sentence Embeddings** ‚Äî and presents results in an **interactive Streamlit dashboard**.

---

## üöÄ Features
- **Parallel Text Preprocessing**: Multi-core tokenization, lemmatization, and stopword removal using SpaCy and Python multiprocessing.  
- **Text Modeling**: Implements both traditional (LDA) and modern (embedding-based K-Means) topic modeling techniques.  
- **Efficient Vectorization**: Uses TF-IDF and CountVectorizer for feature extraction.  
- **Visualization Dashboard**: Interactive Streamlit app comparing K-Means and LDA results.  
- **Performance Metrics**: Includes Silhouette Score, Topic Flow (Sankey Diagram), and Time Comparison charts.  
- **Automatic Topic Labeling**: Uses cosine similarity to assign human-readable topic labels.

---

## üß© System Workflow
1. **Upload Dataset** ‚Üí Upload CSV or text data.  
2. **Preprocessing** ‚Üí Cleaning, lemmatizing, and tokenizing using SpaCy.  
3. **Embedding Generation** ‚Üí Semantic sentence embeddings with SentenceTransformer.  
4. **Dimensionality Reduction** ‚Üí UMAP reduces embeddings for faster clustering.  
5. **Clustering and Topic Modeling** ‚Üí K-Means and LDA applied in parallel.  
6. **Visualization** ‚Üí Interactive Streamlit dashboard showing topics, scores, and time efficiency.

---

## ‚öôÔ∏è Technologies Used
- **Programming Language**: Python  
- **Libraries**: Streamlit, SpaCy, SentenceTransformer, Scikit-learn, UMAP, Matplotlib, Plotly  
- **Parallelism**: Python Multiprocessing module  
- **Visualization**: Plotly, Matplotlib, Streamlit components  

---

## üìä Results
- Parallel preprocessing improved performance by up to **40‚Äì60%** compared to sequential execution.  
- K-Means produced **semantically coherent topics**, while LDA offered **probabilistic interpretability**.  
- Dashboard enables easy comparison of **model performance, topic clarity, and time efficiency**.

---

## üß† Key Concepts
- **Parallelism in NLP**: Enables faster text processing by dividing tasks across CPU cores.  
- **Embedding-based Clustering**: Uses transformer embeddings for meaning-driven topic grouping.  
- **Probabilistic Topic Modeling**: LDA identifies latent topics through word distributions.  

